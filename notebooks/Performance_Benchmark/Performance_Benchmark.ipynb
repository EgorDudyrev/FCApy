{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro\n",
    "\n",
    "There are a number of python packages to work with FCA. In this notebook we will compare their performances in the basic FCA task: constructing the concept lattice from a formal context.\n",
    "\n",
    "We consider three packages: FCApy, fcapsy and Concepts\n",
    "\n",
    "// More packages can be compared in the future"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install competitors libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The current `FCApy` library (by Egor Dudyrev, HSE Moscow): https://github.com/EgorDudyrev/FCApy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install -U fcapy[all] --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fcapy import LIB_INSTALLED\n",
    "from fcapy.context import FormalContext, converters\n",
    "from fcapy.lattice import ConceptLattice\n",
    "from fcapy.visualizer import Visualizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Concepts` package (by Sebastian Bank, University of Leipzig): https://github.com/xflr6/concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install -U concepts --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`fcapsy` package (by Tomáš Mikula, Palacký University): https://github.com/mikulatomas/fcapsy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install -U fcapsy --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fcapsy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we load some classic FCA contexts (datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_classic = {}\n",
    "contexts_to_test = ['animal_movement', 'digits', 'gewaesser',\n",
    "                    'lattice', 'liveinwater', 'tealady']\n",
    "\n",
    "!rm -rf tmp\n",
    "!mkdir tmp\n",
    "\n",
    "for ctx_name in contexts_to_test:\n",
    "    fname = f'tmp/{ctx_name}.cxt'\n",
    "    !wget -O {fname} -q https://raw.githubusercontent.com/EgorDudyrev/FCApy/main/data/{ctx_name}.cxt\n",
    "    ctx = converters.read_cxt(fname)\n",
    "    df = ctx.to_pandas()\n",
    "    df.name = ctx_name\n",
    "    frames_classic[ctx_name] = df\n",
    "!rm -rf tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add Bob-Ross dataset which has more objects and attributes than the classic FCA datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(403, 67)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "ctx_name = 'bob_ross'\n",
    "fname = f\"{ctx_name}.csv\"\n",
    "!wget -O {fname} -q https://raw.githubusercontent.com/fivethirtyeight/data/master/bob-ross/elements-by-episode.csv \n",
    "df = pd.read_csv(fname)\n",
    "df['EPISODE_TITLE'] = df['EPISODE']+' '+df['TITLE']\n",
    "df = df.drop(['EPISODE','TITLE'],1).set_index('EPISODE_TITLE').astype(bool)\n",
    "df.name = ctx_name\n",
    "frames_classic[ctx_name] = df\n",
    "print(df.shape)\n",
    "!rm {fname}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These classic real world contexts are small so we add some big random contexts to our examination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from itertools import product\n",
    "\n",
    "np.random.seed(42)\n",
    "n_objects_vars = [10, 30, 100]\n",
    "n_attributes_vars = [10, 30, 50]\n",
    "densities_vars = [0.1, 0.5, 0.9]\n",
    "frames_random = {}\n",
    "for comb in product(n_objects_vars, n_attributes_vars, densities_vars):\n",
    "    n_objects, n_attributes, density = comb\n",
    "\n",
    "    frame = pd.DataFrame(np.random.binomial(1, density, size=(n_objects,n_attributes)))\n",
    "    frame.columns = [f\"m_{i}\" for i in frame.columns]\n",
    "    frame.index = [f\"g_{i}\" for i in frame.index]\n",
    "    frame = frame.astype(bool)\n",
    "\n",
    "    frame.name = f\"random_{n_objects}_{n_attributes}_{density}\"\n",
    "    frames_random[frame.name] = frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = dict(frames_classic, **frames_random)\n",
    "#frames = dict(frames_classic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run benchmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Default lattice visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us take one classic FCA context 'animal movement' and a bigger one 'bob ross' dataset\n",
    "\n",
    "The description of Animals context:\n",
    "* objects (rows) are Animals\n",
    "* attributes (columns) are Actions\n",
    "* the table shows whether an Animal can perform an Action\n",
    "\n",
    "The description of Bob Ross dataset:\n",
    "* objects (rows) are paintings by Bob Ross\n",
    "* attributes (columns) are specific elements in these paintings\n",
    "* the table shows whether an element is on a painting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx_names = ['animal_movement', 'tealady']#'bob_ross']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "animal_movement\n",
      "(16, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fly</th>\n",
       "      <th>hunt</th>\n",
       "      <th>run</th>\n",
       "      <th>swim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dove</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hen</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>duck</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>goose</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>owl</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         fly   hunt    run   swim\n",
       "dove    True  False  False  False\n",
       "hen    False  False  False  False\n",
       "duck    True  False  False   True\n",
       "goose   True  False  False   True\n",
       "owl     True   True  False  False"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctx_name = ctx_names[0]\n",
    "print(ctx_name)\n",
    "df = frames[ctx_name]\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ctx_name = ctx_names[1]\n",
    "print(ctx_name)\n",
    "df = frames[ctx_name]\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization by `concepts`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The visualization can be found in the file\n",
    "* _lattice_visualization_concepts_animal_movement.png_\n",
    "* _lattice_visualization_concepts_bob_ross.png_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "animal_movement\n",
      "Lattice constructed in 0.001663 seconds\n",
      "Executed in 0.058675 seconds\n",
      "tealady\n",
      "Lattice constructed in 0.006811 seconds\n",
      "Executed in 0.056226 seconds\n"
     ]
    }
   ],
   "source": [
    "for ctx_name in ctx_names:\n",
    "    df = frames[ctx_name]\n",
    "    print(ctx_name)\n",
    "    t1 = datetime.now()\n",
    "    ctx_concepts = concepts.Context(df.index, df.columns, df.values)\n",
    "    ltc_concepts = ctx_concepts.lattice\n",
    "    print(f'Lattice constructed in {(datetime.now()-t1).total_seconds()} seconds')\n",
    "    ltc_concepts.graphviz(f'imgs/lattice_visualization/concepts_{ctx_name}', render=True);\n",
    "    t2 = datetime.now()\n",
    "    dt = (t2-t1).total_seconds()\n",
    "    print(f\"Executed in {dt} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization by `fcapy`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizations can be found in the files\n",
    "* _lattice_visualization_fcapy_networkx_animal_movement.png_ \n",
    "* _lattice_visualization_fcapy_plotly_animal_movement.png_\n",
    "\n",
    "* _lattice_visualization_fcapy_networkx_bob_ross.png_ \n",
    "* _lattice_visualization_fcapy_plotly_bob_ross.png_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "animal_movement\n",
      "Lattice constructed in 0.041466 seconds\n",
      "Visualizer constructed in 0.042298 seconds\n",
      "Png saved in 0.245663 seconds\n",
      "Executed in 3.016535 seconds\n",
      "tealady\n",
      "Lattice constructed in 0.013088 seconds\n",
      "Visualizer constructed in 0.015431 seconds\n",
      "Png saved in 0.86057 seconds\n",
      "Executed in 1.020402 seconds\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for ctx_name in ctx_names:\n",
    "    df = frames[ctx_name]\n",
    "    print(ctx_name)\n",
    "    \n",
    "    t1 = datetime.now()\n",
    "    ctx_fcapy = FormalContext.from_pandas(df)\n",
    "    ltc_fcapy = ConceptLattice.from_context(ctx_fcapy)\n",
    "    print(f'Lattice constructed in {(datetime.now()-t1).total_seconds()} seconds')\n",
    "    vsl_fcapy = Visualizer(ltc_fcapy)\n",
    "    print(f'Visualizer constructed in {(datetime.now()-t1).total_seconds()} seconds')\n",
    "\n",
    "    plt.title('Networkx lattice')\n",
    "    vsl_fcapy.draw_networkx()\n",
    "    plt.savefig(f'imgs/lattice_visualization/fcapy_networkx_{ctx_name}.png')\n",
    "    plt.close()\n",
    "    print(f'Png saved in {(datetime.now()-t1).total_seconds()} seconds')\n",
    "\n",
    "    fig = vsl_fcapy.get_plotly_figure(title='Plotly lattice')\n",
    "    fig.write_image(f'imgs/lattice_visualization/fcapy_plotly_{ctx_name}.png')\n",
    "    t2 = datetime.now()\n",
    "    dt = (t2-t1).total_seconds()\n",
    "    print(f'Executed in {dt} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time to construct a lattice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions to run the same lattice construction task with different libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_context_by_lib(frame, lib_name):\n",
    "    if lib_name == 'concepts':\n",
    "        context = concepts.Context(frame.index, frame.columns, frame.values)\n",
    "    elif lib_name == 'fcapy':\n",
    "        context = FormalContext.from_pandas(frame)\n",
    "    elif lib_name == 'fcapsy':\n",
    "        context = fcapsy.Context.from_pandas(frame)\n",
    "    else:\n",
    "        raise ValueError(f'Given library \"{lib_name}\" is not supported')\n",
    "        \n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_intent_extent_time_by_func(objects, attributes, extent_func, intent_func, samples_per_size=100):\n",
    "    times = []\n",
    "    for arr, fnc in [(objects, intent_func), (attributes, extent_func)]:\n",
    "        subsample_sizes = np.logspace(0, np.log(len(arr))/np.log(10), 10).round(0).astype(int)    \n",
    "        np.random.seed(42)\n",
    "        samples = [sample for size in subsample_sizes for sample in np.random.choice(arr, size=(samples_per_size, size))]\n",
    "        \n",
    "        t1 = datetime.now()\n",
    "        intents = [fnc(sample) for sample in samples]\n",
    "        t2 = datetime.now()\n",
    "        dt = (t2-t1).total_seconds()/len(samples) \n",
    "        times.append(dt)\n",
    "    intent_time, extent_time = times\n",
    "    \n",
    "    return intent_time, extent_time\n",
    "\n",
    "\n",
    "def test_intent_extent_time_by_lib(frame, context, lib_name, samples_per_size=100):\n",
    "    if lib_name == 'concepts':\n",
    "        intent_time, extent_time = test_intent_extent_time_by_func(\n",
    "            frame.index, frame.columns, context.extension, context.intension, samples_per_size)\n",
    "    elif lib_name == 'fcapy':\n",
    "        intent_time, extent_time = test_intent_extent_time_by_func(\n",
    "            frame.index, frame.columns, context.extension, context.intention, samples_per_size)\n",
    "    elif lib_name == 'fcapsy':\n",
    "        intent_time, extent_time = test_intent_extent_time_by_func(\n",
    "            frame.index, frame.columns,\n",
    "            lambda ar: context.down(context.Attributes(ar)),\n",
    "            lambda ar: context.up(context.Objects(ar)),\n",
    "            samples_per_size\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(f'Given library \"{lib_name}\" is not supported')\n",
    "        \n",
    "    return intent_time, extent_time\n",
    "\n",
    "\n",
    "def test_intent_extent_time_by_lib_multiprocess(frame, context, lib_name, intent_time, extent_time, samples_per_size=100):\n",
    "    intent_time.value, extent_time.value = test_intent_extent_time_by_lib(frame, context, lib_name, samples_per_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_lattice_time_by_func(context, lattice_func):\n",
    "    t1 = datetime.now()\n",
    "    ltc = lattice_func(context)\n",
    "    t2 = datetime.now()\n",
    "    dt = (t2-t1).total_seconds()\n",
    "    return dt\n",
    "\n",
    "def test_lattice_time_by_lib(context, lib_name):\n",
    "    if lib_name == 'concepts':\n",
    "        lattice_time = test_lattice_time_by_func(context, lambda ctx: ctx.lattice)\n",
    "    elif lib_name == 'fcapy':\n",
    "        lattice_time = test_lattice_time_by_func(context, lambda ctx: ConceptLattice.from_context(ctx, algo='CbO'))\n",
    "    elif lib_name == 'fcapsy':\n",
    "        lattice_time = test_lattice_time_by_func(context, lambda ctx: fcapsy.Lattice.from_context(ctx))\n",
    "    else:\n",
    "        raise ValueError(f'Given library \"{lib_name}\" is not supported')\n",
    "\n",
    "    return lattice_time\n",
    "\n",
    "def test_lattice_time_by_lib_multiprocess(context, lib_name, lattice_time):\n",
    "    lattice_time.value = test_lattice_time_by_lib(context, lib_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "def run_func_multiprocess(frame, lib_name, timeout_seconds):\n",
    "    context = construct_context_by_lib(frame, lib_name)\n",
    "    \n",
    "    lattice_time, intent_time, extent_time = [multiprocessing.Value('f', -1, lock=False) for _ in range(3)]\n",
    "    \n",
    "    p = multiprocessing.Process(\n",
    "        target=test_intent_extent_time_by_lib_multiprocess,\n",
    "        name=f\"test_intent_extent_{lib_name}\",\n",
    "        args=[frame, context, lib_name, intent_time, extent_time, 1000])\n",
    "    p.start()\n",
    "    p.join(timeout_seconds)\n",
    "    if p.is_alive():    \n",
    "        p.terminate()\n",
    "        \n",
    "    p = multiprocessing.Process(\n",
    "        target=test_lattice_time_by_lib_multiprocess,\n",
    "        name=f\"test_lattice_{lib_name}\",\n",
    "        args=[context, lib_name, lattice_time])\n",
    "    p.start()\n",
    "    p.join(timeout_seconds)\n",
    "    if p.is_alive():    \n",
    "        p.terminate()\n",
    "        \n",
    "    def neg1_to_none(multiprocess_var):\n",
    "        return multiprocess_var.value if multiprocess_var.value != -1 else None\n",
    "\n",
    "    stat = {\n",
    "        'lattice_construction_time (secs)': neg1_to_none(lattice_time),\n",
    "        'intent_time (secs)': neg1_to_none(intent_time),\n",
    "        'extent_time (secs)': neg1_to_none(extent_time),\n",
    "        'timeout_seconds': timeout_seconds,\n",
    "    }\n",
    "    return stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_context_stat(frame):\n",
    "    ctx_stat = {\n",
    "        'ctx_name': frame.name,\n",
    "        'n_objects': frame.shape[0], 'n_attributes': frame.shape[1],\n",
    "        'n_connections': frame.sum().sum(),\n",
    "        'density': frame.sum().sum()/(frame.shape[0]*frame.shape[1]),\n",
    "        'is_random': frame.name.startswith('random')\n",
    "    }\n",
    "    return ctx_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_order = sorted(frames, key=lambda ctx_name: get_context_stat(frames[ctx_name])['n_connections'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_runs = 10\n",
    "timeout_secs = 5*60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1020\n"
     ]
    }
   ],
   "source": [
    "run_number_vals = list(range(n_runs))\n",
    "ctx_names_vals = frames_order\n",
    "lib_names_vals = ['concepts', 'fcapy', 'fcapsy']\n",
    "all_combs = list(product(run_number_vals, ctx_names_vals, lib_names_vals))\n",
    "print(len(all_combs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_df = pd.DataFrame(all_combs, columns=['run_number', 'ctx_name', 'lib_name'])\n",
    "stats_df['is_computed'] = False\n",
    "stats_df.to_csv('benchmark_stats_tmp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33f8a4a98fde4692859f56f990ec54a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1020.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 26.2 s, sys: 10.5 s, total: 36.7 s\n",
      "Wall time: 15h 4min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df_to_compute = stats_df[~stats_df['is_computed']][['run_number','ctx_name','lib_name']]\n",
    "for comb in tqdm(df_to_compute.iterrows(), total=len(df_to_compute)):\n",
    "    stats_df = pd.read_csv('benchmark_stats_tmp.csv', index_col=0)\n",
    "    row_idx, (run_number, ctx_name, lib_name) = comb\n",
    "    \n",
    "    frame = frames[ctx_name]\n",
    "    frame_stat = get_context_stat(frame)\n",
    "    \n",
    "    stat = run_func_multiprocess(frame, lib_name, timeout_seconds=timeout_secs)\n",
    "    stat = dict(stat, **frame_stat)\n",
    "    \n",
    "    for k,v in stat.items():\n",
    "        stats_df.loc[row_idx, k] = v\n",
    "    stats_df.loc[row_idx, 'is_computed'] = True\n",
    "    \n",
    "    stats_df.to_csv('benchmark_stats_tmp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp benchmark_stats_tmp.csv benchmark_stats.csv\n",
    "!rm benchmark_stats_tmp.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1020, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_number</th>\n",
       "      <th>ctx_name</th>\n",
       "      <th>lib_name</th>\n",
       "      <th>is_computed</th>\n",
       "      <th>lattice_construction_time (secs)</th>\n",
       "      <th>intent_time (secs)</th>\n",
       "      <th>extent_time (secs)</th>\n",
       "      <th>timeout_seconds</th>\n",
       "      <th>n_objects</th>\n",
       "      <th>n_attributes</th>\n",
       "      <th>n_connections</th>\n",
       "      <th>density</th>\n",
       "      <th>is_random</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>random_10_10_0.1</td>\n",
       "      <td>concepts</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000661</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>300.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.090</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>random_10_10_0.1</td>\n",
       "      <td>fcapy</td>\n",
       "      <td>True</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>300.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.090</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>random_10_10_0.1</td>\n",
       "      <td>fcapsy</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000537</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>300.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.090</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>animal_movement</td>\n",
       "      <td>concepts</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000837</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>300.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.375</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>animal_movement</td>\n",
       "      <td>fcapy</td>\n",
       "      <td>True</td>\n",
       "      <td>0.002259</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>300.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.375</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   run_number          ctx_name  lib_name  is_computed  \\\n",
       "0           0  random_10_10_0.1  concepts         True   \n",
       "1           0  random_10_10_0.1     fcapy         True   \n",
       "2           0  random_10_10_0.1    fcapsy         True   \n",
       "3           0   animal_movement  concepts         True   \n",
       "4           0   animal_movement     fcapy         True   \n",
       "\n",
       "   lattice_construction_time (secs)  intent_time (secs)  extent_time (secs)  \\\n",
       "0                          0.000661            0.000006            0.000005   \n",
       "1                          0.001700            0.000005            0.000006   \n",
       "2                          0.000537            0.000006            0.000004   \n",
       "3                          0.000837            0.000006            0.000004   \n",
       "4                          0.002259            0.000005            0.000007   \n",
       "\n",
       "   timeout_seconds  n_objects  n_attributes  n_connections  density  is_random  \n",
       "0            300.0       10.0          10.0            9.0    0.090       True  \n",
       "1            300.0       10.0          10.0            9.0    0.090       True  \n",
       "2            300.0       10.0          10.0            9.0    0.090       True  \n",
       "3            300.0       16.0           4.0           24.0    0.375      False  \n",
       "4            300.0       16.0           4.0           24.0    0.375      False  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats_df = pd.read_csv('benchmark_stats.csv', index_col=0)\n",
    "print(stats_df.shape)\n",
    "stats_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_df = stats_df.fillna(timeout_secs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Benchmark results can be found in the file:\n",
    "* _latice_construction_statistics.csv_\n",
    "\n",
    "Contexts statistics (num. of objects, attributes, e.t.c) is in the file:\n",
    "* _context_statistics.csv_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_stat_feats = ['n_objects', 'n_attributes', 'n_connections', 'density']\n",
    "context_stat_df = stats_df[['ctx_name',]+context_stat_feats].drop_duplicates().reset_index(drop=True)\n",
    "context_stat_df.to_csv('context_statistics.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do not draw any plots in this notebook in order for Github to render it.\n",
    "\n",
    "Benchmark plot can be found in the files:\n",
    "* _lattice_construction_time_for_classic_contexts.png_\n",
    "* _lattice_construction_time_for_random_contexts.png_\n",
    "* _lattice_construction_time_all_data.png_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.facecolor'] = (1,1,1,1)  # (1,1,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_feat = 'lattice_construction_time (secs)'\n",
    "width = 2\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for idx, x_feat in enumerate(context_stat_feats):\n",
    "    plt.subplot(len(context_stat_feats)//width+1, width, idx+1)\n",
    "    sns.lineplot(x=x_feat, y=y_feat, hue='lib_name', data=stats_df[~stats_df['is_random']])\n",
    "    plt.xlabel(''); plt.ylabel('')\n",
    "    plt.title(x_feat)\n",
    "    plt.xlabel(x_feat)\n",
    "    plt.ylabel('time (secs)')\n",
    "    plt.axhline(timeout_secs, linestyle='--', color='grey') #label='maximal time per run')\n",
    "    plt.text(plt.xlim()[1]*0.6, timeout_secs*1.05, 'maximal time per run')\n",
    "    plt.ylim(-1, timeout_secs*1.2)\n",
    "    plt.legend()\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=0.9)\n",
    "plt.suptitle(f\"{y_feat} based on context statistics\\n(for classic fca contexts)\")\n",
    "plt.savefig('imgs/lattice_construction_time/classic_contexts.png', pad_inches=0.1, bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_stat_feats = ['n_objects', 'n_attributes', 'n_connections', 'density']\n",
    "y_feat = 'lattice_construction_time (secs)'\n",
    "width = 2\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for idx, x_feat in enumerate(context_stat_feats):\n",
    "    plt.subplot(len(context_stat_feats)//width+1, width, idx+1)\n",
    "    sns.lineplot(x=x_feat, y=y_feat, hue='lib_name', data=stats_df[stats_df['is_random']])\n",
    "    plt.xlabel(''); plt.ylabel('')\n",
    "    plt.title(x_feat)\n",
    "    plt.xlabel(x_feat)\n",
    "    plt.ylabel('time (secs)')\n",
    "    plt.axhline(timeout_secs, linestyle='--', color='grey') #label='maximal time per run')\n",
    "    plt.text(plt.xlim()[1]*0.6, timeout_secs*1.05, 'maximal time per run')\n",
    "    plt.ylim(-1, timeout_secs*1.2)\n",
    "    plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=0.9)\n",
    "plt.suptitle(f\"{y_feat} based on context statistics\\n(for random contexts)\")\n",
    "plt.savefig('imgs/lattice_construction_time/random_contexts.png', pad_inches=0.1, bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "context_stat_feats = ['n_objects', 'n_attributes', 'n_connections', 'density']\n",
    "y_feat = 'lattice_construction_time (secs)'\n",
    "width = 2\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for idx, x_feat in enumerate(context_stat_feats):\n",
    "    plt.subplot(len(context_stat_feats)//width+1, width, idx+1)\n",
    "    sns.lineplot(x=x_feat, y=y_feat, hue='lib_name', data=stats_df)\n",
    "    plt.xlabel(''); plt.ylabel('')\n",
    "    plt.title(x_feat)\n",
    "    #plt.yscale('log')\n",
    "    plt.xlabel(x_feat)\n",
    "    plt.ylabel('time (secs)')\n",
    "    plt.axhline(timeout_secs, linestyle='--', color='grey') #label='maximal time per run')\n",
    "    plt.text(plt.xlim()[1]*0.6, timeout_secs*1.05, 'maximal time per run')\n",
    "    plt.ylim(-1, timeout_secs*1.2)\n",
    "    plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=0.9)\n",
    "plt.suptitle(f\"{y_feat} based on context statistics\\n(for random and classic contexts)\")\n",
    "plt.savefig('imgs/lattice_construction_time/all_data.png', pad_inches=0.1, bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_df['intent+extent_time (secs)'] = stats_df[['intent_time (secs)', 'extent_time (secs)']].sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_stat_feats = ['n_objects', 'n_attributes', 'n_connections', 'density']\n",
    "y_feat = 'intent+extent_time (secs)'\n",
    "width = 2\n",
    "\n",
    "plt.figure(figsize=(10,7))\n",
    "for idx, x_feat in enumerate(context_stat_feats):\n",
    "    plt.subplot(len(context_stat_feats)//width+1, width, idx+1)\n",
    "    #sns.lineplot(x=x_feat, y=y_feat, hue='lib_name', data=stats_df)\n",
    "    sns.lineplot(x=stats_df[x_feat], y=stats_df[y_feat]*1e6, hue=stats_df['lib_name'])\n",
    "    plt.xlabel(''); plt.ylabel('')\n",
    "    plt.title(x_feat)\n",
    "    plt.xlabel(x_feat)\n",
    "    plt.ylabel(r'time (microseconds)')\n",
    "    plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=0.9)\n",
    "plt.suptitle(f\"{y_feat} based on context statistics\\n(for random and classic contexts)\")\n",
    "plt.savefig('imgs/intent_extent_time/all_data.png', pad_inches=0.1, bbox_inches='tight')\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
