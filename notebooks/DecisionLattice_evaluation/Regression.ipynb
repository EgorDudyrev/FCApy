{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Processing /opt/jupyter/notebook/dev/dudyrev/FCApy\n",
      "Building wheels for collected packages: fcapy\n",
      "  Building wheel for fcapy (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fcapy: filename=fcapy-0.1.0-py3-none-any.whl size=68513 sha256=70677a6cd60fc65741018d4a9baaa6da270d7f5137d56507770f606dfa8af8e1\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-690yx7oq/wheels/54/75/56/6d37d7ed7625138e16d04981b1bdbbab9942388f67d015cdf0\n",
      "Successfully built fcapy\n",
      "Installing collected packages: fcapy\n",
      "  Attempting uninstall: fcapy\n",
      "    Found existing installation: fcapy 0.1.0\n",
      "    Uninstalling fcapy-0.1.0:\n",
      "      Successfully uninstalled fcapy-0.1.0\n",
      "Successfully installed fcapy-0.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## California housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = fetch_california_housing(as_frame=True)\n",
    "\n",
    "ds = data['data']\n",
    "y_feat = data['target_names'][0]\n",
    "ds[y_feat] = data['target']\n",
    "\n",
    "data_dict['calhouse'] = {\n",
    "    'ds': ds,\n",
    "    'train_feats': data['feature_names'],\n",
    "    'cat_feats': [],\n",
    "    'y_feat': y_feat\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_boston()\n",
    "\n",
    "y_feat = 'price'\n",
    "fs = data['feature_names']\n",
    "ds = pd.DataFrame(data['data'], columns=fs)\n",
    "ds[y_feat] =data['target']\n",
    "\n",
    "data_dict['boston'] = {\n",
    "    'ds': ds,\n",
    "    'train_feats': fs,\n",
    "    'cat_feats': [],\n",
    "    'y_feat': y_feat\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_diabetes(as_frame=True)\n",
    "\n",
    "ds = data['data']\n",
    "y_feat = 'disease'\n",
    "ds[y_feat] = data['target']\n",
    "\n",
    "data_dict['diabetes'] = {\n",
    "    'ds': ds,\n",
    "    'train_feats': data['feature_names'],\n",
    "    'cat_feats': [],\n",
    "    'y_feat': y_feat\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "for data_name in data_dict.keys():\n",
    "    ds = data_dict[data_name]['ds']\n",
    "    cat_feats = data_dict[data_name]['cat_feats']\n",
    "    ds[cat_feats] = ds[cat_feats].astype(str)\n",
    "    for f in cat_feats:\n",
    "        ds[f+'_le'] = LabelEncoder().fit_transform(ds[f])\n",
    "    data_dict[data_name]['ds'] = ds\n",
    "    #train_feats_le = [f+('_le' if f in cat_feats else '') for f in train_feats]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import Pool, CatBoostRegressor\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from datetime import datetime\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from fcapy.mvcontext.mvcontext import MVContext\n",
    "from fcapy.mvcontext import pattern_structure as PS\n",
    "from fcapy.ml.decision_lattice import DecisionLatticeRegressor\n",
    "\n",
    "from collections.abc import Iterable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_catboost(X_train, X_test, y_train, y_test, cat_feats, params):\n",
    "    cb = CatBoostRegressor(\n",
    "        iterations=params.get('n_estimators'),\n",
    "        max_depth=params.get('max_depth'),\n",
    "        thread_count=params.get('n_jobs')\n",
    "    )\n",
    "    \n",
    "    t1 = datetime.now()\n",
    "    pool_train = Pool(X_train, y_train, cat_features=cat_feats)\n",
    "    pool_test = Pool(X_test, cat_features=cat_feats)\n",
    "    \n",
    "    cb.fit(pool_train, verbose=False, plot=False)\n",
    "    t2 = datetime.now()\n",
    "    dt = (t2-t1).total_seconds()\n",
    "    \n",
    "    preds_train = cb.predict(pool_train)\n",
    "    preds_test = cb.predict(pool_test)\n",
    "    \n",
    "    return dt, preds_train, preds_test, cb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_by_fca(dl, X):\n",
    "    pattern_types = {f: PS.IntervalPS for f in X.columns}\n",
    "    mvctx = MVContext(\n",
    "        X.values,\n",
    "        attribute_names=X.columns,\n",
    "        pattern_types=pattern_types\n",
    "    )\n",
    "    preds = dl.predict(mvctx)\n",
    "    preds = [dl.lattice.top_concept.measures['mean_y'] if x is None else x for x in preds]\n",
    "    \n",
    "    return preds\n",
    "\n",
    "def test_fca(X_train, X_test, y_train, y_test, params):\n",
    "    dl = DecisionLatticeRegressor(**params)\n",
    "    \n",
    "    t1 = datetime.now()\n",
    "    pattern_types = {f: PS.IntervalPS for f in X_train.columns}\n",
    "    mvctx_train = MVContext(\n",
    "        X_train.values, target=y_train.values,\n",
    "        attribute_names=X_train.columns,\n",
    "        pattern_types=pattern_types\n",
    "    )\n",
    "    dl.fit(mvctx_train)\n",
    "    t2 = datetime.now()\n",
    "    dt = (t2-t1).total_seconds()\n",
    "    \n",
    "    preds_train = predict_by_fca(dl, X_train)\n",
    "    preds_test = predict_by_fca(dl, X_test)\n",
    "    \n",
    "    return dt, preds_train, preds_test, dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_sklearn_like(X_train, X_test, y_train, y_test, cls, params):\n",
    "    cls_params = inspect.signature(cls.__init__).parameters\n",
    "    cls_params = {k: v for k,v in params.items() if k in cls_params}\n",
    "    \n",
    "    model = cls(**cls_params)\n",
    "    \n",
    "    t1 = datetime.now()\n",
    "    model.fit(X_train, y_train)\n",
    "    t2 = datetime.now()\n",
    "    dt = (t2-t1).total_seconds()\n",
    "    \n",
    "    preds_train = model.predict(X_train)\n",
    "    preds_test = model.predict(X_test)\n",
    "    \n",
    "    return dt, preds_train, preds_test, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(X_train, X_test, y_train, y_test, cls, cat_feats, params):\n",
    "    if cls == CatBoostRegressor:\n",
    "        output = test_catboost(X_train, X_test, y_train, y_test, cat_feats, params)\n",
    "    elif cls == DecisionLatticeRegressor:\n",
    "        output = test_fca(X_train, X_test, y_train, y_test, params)\n",
    "    else:\n",
    "        output = test_sklearn_like(X_train, X_test, y_train, y_test, cls, params)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_metrics(y_train, y_test, preds_train, preds_test):\n",
    "    metrics_dict = {}\n",
    "    for m_name, m_func in [\n",
    "        ('mse', mean_squared_error),\n",
    "        ('mae', mean_absolute_error),\n",
    "        ('r2', r2_score)\n",
    "    ]:\n",
    "        for ds_type in ['train', 'test']:\n",
    "            y = y_train if ds_type == 'train' else y_test\n",
    "            p = preds_train if ds_type == 'train' else preds_test\n",
    "            metrics_dict[f\"{m_name}_{ds_type}\"] = m_func(y, p)\n",
    "\n",
    "    return metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_stat_dict(cls, data_name, kf_idx, train_idxs, test_idxs, params, metrics_dict, dt):\n",
    "    stat = {\n",
    "        'model': cls.__name__,\n",
    "        'ds': data_name,\n",
    "        'fold_id': kf_idx,\n",
    "        'train_size': len(train_idxs),\n",
    "        'test_size': len(test_idxs),\n",
    "        'time': dt\n",
    "    }\n",
    "    stat = dict(stat, **{f\"param_{k}\":v for k,v in params.items()})\n",
    "    stat = dict(stat, **{f\"metric_{k}\":v for k,v in metrics_dict.items()})\n",
    "    return stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 42\n",
    "\n",
    "model_params_vars = [\n",
    "    (DecisionTreeRegressor, dict()),\n",
    "    (RandomForestRegressor, dict(n_estimators=5, max_depth=10)),\n",
    "    (RandomForestRegressor, dict()),\n",
    "    (GradientBoostingRegressor, dict()),\n",
    "    (LGBMRegressor, dict()),\n",
    "    (CatBoostRegressor, dict()),\n",
    "    (DecisionLatticeRegressor,\n",
    "     dict(\n",
    "        algo='RandomForest',\n",
    "        algo_params={'rf_params':{'n_estimators':5, 'max_depth':10,}}\n",
    "     )),\n",
    "    (DecisionLatticeRegressor,\n",
    "     dict(\n",
    "        algo='RandomForest',\n",
    "        algo_params={'rf_params':{'n_estimators':10, 'max_depth':10,}}\n",
    "     )),\n",
    "    (DecisionLatticeRegressor,\n",
    "     dict(\n",
    "         algo='Sofia',\n",
    "         algo_params={'L_max': 100}\n",
    "     )\n",
    "    )\n",
    "]\n",
    "model_params_vars = [\n",
    "    (cls, dict({'random_state':random_state}, **params))\n",
    "    for cls, params in model_params_vars\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "kf = KFold(n_splits=5)\n",
    "stat_ds = []\n",
    "\n",
    "for data_name, data in tqdm(data_dict.items(), desc='iterate datasets'):\n",
    "    ds, train_feats, cat_feats, y_feat = data['ds'], data['train_feats'], data['cat_feats'], data['y_feat']\n",
    "    train_feats_le = [f+('_le' if f in cat_feats else '') for f in train_feats]\n",
    "\n",
    "    for kf_idx, idxs in tqdm(enumerate(kf.split(ds[train_feats])), desc='KFold', total=kf.n_splits, leave=False):\n",
    "        train_idxs, test_idxs = idxs\n",
    "        ds_train, ds_test = ds.loc[train_idxs], ds.loc[test_idxs]\n",
    "        \n",
    "        #if kf_idx==1:\n",
    "        #    break\n",
    "        \n",
    "        for cls, params in tqdm(model_params_vars, leave=False, desc='iterate models'):\n",
    "            if cls == DecisionLatticeRegressor and params['algo'] == 'Sofia' and len(train_idxs)>5000:\n",
    "                continue\n",
    "            \n",
    "            train_feats_ = train_feats if cls == CatBoostRegressor else train_feats_le\n",
    "            \n",
    "            res = test_model(\n",
    "                ds_train[train_feats_], ds_test[train_feats_], ds_train[y_feat], ds_test[y_feat],\n",
    "                cls, cat_feats, params\n",
    "            )\n",
    "            dt, preds_train, preds_test, model = res\n",
    "            \n",
    "            metrics_dict = calc_metrics(ds_train[y_feat], ds_test[y_feat], preds_train, preds_test)\n",
    "            \n",
    "            stat = create_stat_dict(cls, data_name, kf_idx, train_idxs, test_idxs, params, metrics_dict, dt)\n",
    "            stat_ds.append(pd.Series(stat))\n",
    "            \n",
    "            if cls == DecisionLatticeRegressor:\n",
    "                model.use_generators = True\n",
    "                pattern_types = {f: PS.IntervalPS for f in train_feats_}\n",
    "                mvctx = MVContext(\n",
    "                    ds_train[train_feats_].values, pattern_types, \n",
    "                    attribute_names=train_feats_,\n",
    "                )\n",
    "                \n",
    "                for gen_algo in ['approximate', 'exact']:\n",
    "                    if gen_algo == 'exact' and params['algo'] == 'RandomForest' \\\n",
    "                        and params['algo_params']['rf_params']['n_estimators'] > 10:\n",
    "                        continue\n",
    "                        \n",
    "                    if gen_algo == 'exact' and len(train_idxs) > 3000:\n",
    "                        continue\n",
    "                        \n",
    "                    params = dict(params, gen_algo=gen_algo)\n",
    "                    \n",
    "                    t1 = datetime.now()\n",
    "                    model.compute_generators(mvctx, gen_algo, use_tqdm=gen_algo=='exact')\n",
    "                    t2 = datetime.now()\n",
    "                    dt_gen = (t2-t1).total_seconds()\n",
    "                    \n",
    "                    preds_train = predict_by_fca(model, ds_train[train_feats_])\n",
    "                    preds_test = predict_by_fca(model, ds_test[train_feats_])\n",
    "                    metrics_dict = calc_metrics(ds_train[y_feat], ds_test[y_feat], preds_train, preds_test)\n",
    "                    stat = create_stat_dict(cls, data_name, kf_idx, train_idxs, test_idxs, params, metrics_dict, dt+dt_gen)\n",
    "                    stat_ds.append(pd.Series(stat))\n",
    "                        \n",
    "                    \n",
    "        pd.concat(stat_ds,1, sort=False).T.to_csv('tmp_evaluation_regr.csv')\n",
    "pd.concat(stat_ds,1, sort=False).T.to_csv('evaluation_regr_full1.csv')\n",
    "!rm tmp_evaluation_regr.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Weighted Average Percentage Error post factum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>ds</th>\n",
       "      <th>fold_id</th>\n",
       "      <th>train_size</th>\n",
       "      <th>test_size</th>\n",
       "      <th>time</th>\n",
       "      <th>param_random_state</th>\n",
       "      <th>metric_mse_train</th>\n",
       "      <th>metric_mse_test</th>\n",
       "      <th>metric_mae_train</th>\n",
       "      <th>metric_mae_test</th>\n",
       "      <th>metric_r2_train</th>\n",
       "      <th>metric_r2_test</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_algo</th>\n",
       "      <th>param_algo_params</th>\n",
       "      <th>param_gen_algo</th>\n",
       "      <th>metric_wape_train</th>\n",
       "      <th>metric_wape_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>calhouse</td>\n",
       "      <td>0</td>\n",
       "      <td>16512</td>\n",
       "      <td>4128</td>\n",
       "      <td>0.151587</td>\n",
       "      <td>42</td>\n",
       "      <td>1.051528e-31</td>\n",
       "      <td>0.793655</td>\n",
       "      <td>4.867984e-17</td>\n",
       "      <td>0.623827</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.261216</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.248564e-17</td>\n",
       "      <td>0.370648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>calhouse</td>\n",
       "      <td>0</td>\n",
       "      <td>16512</td>\n",
       "      <td>4128</td>\n",
       "      <td>0.277177</td>\n",
       "      <td>42</td>\n",
       "      <td>2.019904e-01</td>\n",
       "      <td>0.599036</td>\n",
       "      <td>3.110937e-01</td>\n",
       "      <td>0.580684</td>\n",
       "      <td>0.850314</td>\n",
       "      <td>0.442380</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.436969e-01</td>\n",
       "      <td>0.345015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>calhouse</td>\n",
       "      <td>0</td>\n",
       "      <td>16512</td>\n",
       "      <td>4128</td>\n",
       "      <td>9.033681</td>\n",
       "      <td>42</td>\n",
       "      <td>3.465075e-02</td>\n",
       "      <td>0.521694</td>\n",
       "      <td>1.203863e-01</td>\n",
       "      <td>0.543827</td>\n",
       "      <td>0.974322</td>\n",
       "      <td>0.514374</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.560749e-02</td>\n",
       "      <td>0.323116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>calhouse</td>\n",
       "      <td>0</td>\n",
       "      <td>16512</td>\n",
       "      <td>4128</td>\n",
       "      <td>2.807599</td>\n",
       "      <td>42</td>\n",
       "      <td>2.649648e-01</td>\n",
       "      <td>0.427120</td>\n",
       "      <td>3.613307e-01</td>\n",
       "      <td>0.523329</td>\n",
       "      <td>0.803647</td>\n",
       "      <td>0.602410</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.669018e-01</td>\n",
       "      <td>0.310937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>calhouse</td>\n",
       "      <td>0</td>\n",
       "      <td>16512</td>\n",
       "      <td>4128</td>\n",
       "      <td>200.734206</td>\n",
       "      <td>42</td>\n",
       "      <td>1.627876e-01</td>\n",
       "      <td>0.370611</td>\n",
       "      <td>2.791399e-01</td>\n",
       "      <td>0.446897</td>\n",
       "      <td>0.879366</td>\n",
       "      <td>0.655012</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.289371e-01</td>\n",
       "      <td>0.265525</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       model        ds  fold_id  train_size  test_size  \\\n",
       "0      DecisionTreeRegressor  calhouse        0       16512       4128   \n",
       "1      RandomForestRegressor  calhouse        0       16512       4128   \n",
       "2      RandomForestRegressor  calhouse        0       16512       4128   \n",
       "3  GradientBoostingRegressor  calhouse        0       16512       4128   \n",
       "4              LGBMRegressor  calhouse        0       16512       4128   \n",
       "\n",
       "         time  param_random_state  metric_mse_train  metric_mse_test  \\\n",
       "0    0.151587                  42      1.051528e-31         0.793655   \n",
       "1    0.277177                  42      2.019904e-01         0.599036   \n",
       "2    9.033681                  42      3.465075e-02         0.521694   \n",
       "3    2.807599                  42      2.649648e-01         0.427120   \n",
       "4  200.734206                  42      1.627876e-01         0.370611   \n",
       "\n",
       "   metric_mae_train  metric_mae_test  metric_r2_train  metric_r2_test  \\\n",
       "0      4.867984e-17         0.623827         1.000000        0.261216   \n",
       "1      3.110937e-01         0.580684         0.850314        0.442380   \n",
       "2      1.203863e-01         0.543827         0.974322        0.514374   \n",
       "3      3.613307e-01         0.523329         0.803647        0.602410   \n",
       "4      2.791399e-01         0.446897         0.879366        0.655012   \n",
       "\n",
       "   param_n_estimators  param_max_depth param_algo param_algo_params  \\\n",
       "0                 NaN              NaN        NaN               NaN   \n",
       "1                 5.0             10.0        NaN               NaN   \n",
       "2                 NaN              NaN        NaN               NaN   \n",
       "3                 NaN              NaN        NaN               NaN   \n",
       "4                 NaN              NaN        NaN               NaN   \n",
       "\n",
       "  param_gen_algo  metric_wape_train  metric_wape_test  \n",
       "0            NaN       2.248564e-17          0.370648  \n",
       "1            NaN       1.436969e-01          0.345015  \n",
       "2            NaN       5.560749e-02          0.323116  \n",
       "3            NaN       1.669018e-01          0.310937  \n",
       "4            NaN       1.289371e-01          0.265525  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stat_ds = pd.read_csv('evaluation_regr_full1.csv', index_col=0)\n",
    "stat_ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_ds[f'metric_wape_train'] = None\n",
    "stat_ds[f'metric_wape_test'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iterate datasets:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "KFold:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "                                            \u001b[A\n",
      "KFold:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "                                            \u001b[A\n",
      "KFold:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "iterate datasets: 100%|██████████| 3/3 [00:00<00:00, 25.78it/s]\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "\n",
    "for data_name, data in tqdm(data_dict.items(), desc='iterate datasets'):\n",
    "    ds, train_feats, cat_feats, y_feat = data['ds'], data['train_feats'], data['cat_feats'], data['y_feat']\n",
    "\n",
    "    for kf_idx, idxs in tqdm(enumerate(kf.split(ds[train_feats])), desc='KFold', total=kf.n_splits, leave=False):\n",
    "        train_idxs, test_idxs = idxs\n",
    "        y_train = ds.loc[train_idxs, y_feat]\n",
    "        y_test = ds.loc[test_idxs, y_feat]\n",
    "        \n",
    "        flg = (stat_ds['ds']==data_name)&(stat_ds['fold_id']==kf_idx)\n",
    "        stat_ds.loc[flg, 'metric_wape_train'] = stat_ds.loc[flg, 'metric_mae_train']/y_train.mean()\n",
    "        stat_ds.loc[flg, 'metric_wape_test'] = stat_ds.loc[flg, 'metric_mae_test']/y_test.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_ds.to_csv('evaluation_regr_full1.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
