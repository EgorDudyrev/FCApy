{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///home/egor/Documents/FCApy\n",
      "Installing collected packages: fcapy\n",
      "  Attempting uninstall: fcapy\n",
      "    Found existing installation: fcapy 0.1.2\n",
      "    Uninstalling fcapy-0.1.2:\n",
      "      Successfully uninstalled fcapy-0.1.2\n",
      "  Running setup.py develop for fcapy\n",
      "Successfully installed fcapy\n"
     ]
    }
   ],
   "source": [
    "!pip install -e ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## California housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = fetch_california_housing(as_frame=True)\n",
    "\n",
    "ds = data['data']\n",
    "y_feat = data['target_names'][0]\n",
    "ds[y_feat] = data['target']\n",
    "\n",
    "data_dict['calhouse'] = {\n",
    "    'ds': ds,\n",
    "    'train_feats': data['feature_names'],\n",
    "    'cat_feats': [],\n",
    "    'y_feat': y_feat\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_boston()\n",
    "\n",
    "y_feat = 'price'\n",
    "fs = data['feature_names']\n",
    "ds = pd.DataFrame(data['data'], columns=fs)\n",
    "ds[y_feat] =data['target']\n",
    "\n",
    "data_dict['boston'] = {\n",
    "    'ds': ds,\n",
    "    'train_feats': fs,\n",
    "    'cat_feats': [],\n",
    "    'y_feat': y_feat\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_diabetes(as_frame=True)\n",
    "\n",
    "ds = data['data']\n",
    "y_feat = 'disease'\n",
    "ds[y_feat] = data['target']\n",
    "\n",
    "data_dict['diabetes'] = {\n",
    "    'ds': ds,\n",
    "    'train_feats': data['feature_names'],\n",
    "    'cat_feats': [],\n",
    "    'y_feat': y_feat\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "for data_name in data_dict.keys():\n",
    "    ds = data_dict[data_name]['ds']\n",
    "    cat_feats = data_dict[data_name]['cat_feats']\n",
    "    ds[cat_feats] = ds[cat_feats].astype(str)\n",
    "    for f in cat_feats:\n",
    "        ds[f+'_le'] = LabelEncoder().fit_transform(ds[f])\n",
    "    data_dict[data_name]['ds'] = ds\n",
    "    #train_feats_le = [f+('_le' if f in cat_feats else '') for f in train_feats]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from datetime import datetime\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from fcapy.mvcontext.mvcontext import MVContext\n",
    "from fcapy.mvcontext import pattern_structure as PS\n",
    "from fcapy.ml.decision_lattice import DecisionLatticeRegressor\n",
    "\n",
    "from collections.abc import Iterable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def form_output(model, params, dt, preds_train, preds_test):\n",
    "    output = {\n",
    "        'model': model,\n",
    "        'params': params,\n",
    "        'dt': dt,\n",
    "        'preds_train': preds_train,\n",
    "        'preds_test': preds_test,\n",
    "    }\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_decision_tree(X_train, y_train, X_test, all_params):\n",
    "    params = inspect.signature(DecisionTreeRegressor.__init__).parameters\n",
    "    params = {k: v for k,v in all_params.items() if k in params}\n",
    "    \n",
    "    model = DecisionTreeRegressor(**params)\n",
    "    t1 = datetime.now()\n",
    "    model.fit(X_train, y_train)\n",
    "    t2 = datetime.now()\n",
    "    dt = (t2-t1).total_seconds()\n",
    "    \n",
    "    preds_train = model.predict(X_train)\n",
    "    preds_test = model.predict(X_test)\n",
    "    \n",
    "    return form_output(model, params, dt, preds_train, preds_test)\n",
    "\n",
    "def fit_random_forest(X_train, y_train, X_test, all_params):\n",
    "    params = inspect.signature(RandomForestRegressor.__init__).parameters\n",
    "    params = {k: v for k,v in all_params.items() if k in params}\n",
    "    \n",
    "    model = RandomForestRegressor(**params)\n",
    "    t1 = datetime.now()\n",
    "    model.fit(X_train, y_train)\n",
    "    t2 = datetime.now()\n",
    "    dt = (t2-t1).total_seconds()\n",
    "    \n",
    "    preds_train = model.predict(X_train)\n",
    "    preds_test = model.predict(X_test)\n",
    "    \n",
    "    return form_output(model, params, dt, preds_train, preds_test)\n",
    "\n",
    "def fit_gradient_boosting(X_train, y_train, X_test, all_params):\n",
    "    params = inspect.signature(GradientBoostingRegressor.__init__).parameters\n",
    "    params = {k: v for k,v in all_params.items() if k in params}\n",
    "    \n",
    "    model = GradientBoostingRegressor(**params)\n",
    "    t1 = datetime.now()\n",
    "    model.fit(X_train, y_train)\n",
    "    t2 = datetime.now()\n",
    "    dt = (t2-t1).total_seconds()\n",
    "    \n",
    "    preds_train = model.predict(X_train)\n",
    "    preds_test = model.predict(X_test)\n",
    "    \n",
    "    return form_output(model, params, dt, preds_train, preds_test)\n",
    "\n",
    "def fit_xgboost(X_train, y_train, X_test, all_params):\n",
    "    #params = inspect.signature(XGBRegressor.__init__).parameters\n",
    "    params = {'n_estimators', 'max_depth'}\n",
    "    params = {k: v for k,v in all_params.items() if k in params}\n",
    "    \n",
    "    model = XGBRegressor(**params)\n",
    "    t1 = datetime.now()\n",
    "    model.fit(X_train, y_train)\n",
    "    t2 = datetime.now()\n",
    "    dt = (t2-t1).total_seconds()\n",
    "    \n",
    "    preds_train = model.predict(X_train)\n",
    "    preds_test = model.predict(X_test)\n",
    "    \n",
    "    return form_output(model, params, dt, preds_train, preds_test)\n",
    "\n",
    "def fit_model(X_train, y_train, X_test, all_params, model_class):\n",
    "    if model_class == DecisionTreeRegressor:\n",
    "        output = fit_decision_tree(X_train, y_train, X_test, all_params)\n",
    "    elif model_class == RandomForestRegressor:\n",
    "        output = fit_random_forest(X_train, y_train, X_test, all_params)\n",
    "    elif model_class == GradientBoostingRegressor:\n",
    "        output = fit_gradient_boosting(X_train, y_train, X_test, all_params)\n",
    "    elif model_class == XGBRegressor:\n",
    "        output = fit_xgboost(X_train, y_train, X_test, all_params)\n",
    "    else:\n",
    "        raise ValueError\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_dl_dt(K_train, K_test, model):\n",
    "    t1 = datetime.now()\n",
    "    model = DecisionLatticeRegressor.from_decision_tree(model, K_train)\n",
    "    t2 = datetime.now()\n",
    "    dt = (t2-t1).total_seconds()\n",
    "    \n",
    "    preds_train = model.predict(K_train)\n",
    "    preds_test = model.predict(K_test)\n",
    "    \n",
    "    return form_output(model, {}, dt, preds_train, preds_test)\n",
    "\n",
    "def fit_dl_rf(K_train, K_test, model):\n",
    "    t1 = datetime.now()\n",
    "    model = DecisionLatticeRegressor.from_random_forest(model, K_train)\n",
    "    t2 = datetime.now()\n",
    "    dt = (t2-t1).total_seconds()\n",
    "    \n",
    "    preds_train = model.predict(K_train)\n",
    "    preds_test = model.predict(K_test)\n",
    "    \n",
    "    return form_output(model, {}, dt, preds_train, preds_test)\n",
    "\n",
    "def fit_dl_gb(K_train, K_test, model):\n",
    "    t1 = datetime.now()\n",
    "    model = DecisionLatticeRegressor.from_gradient_boosting(model, K_train)\n",
    "    t2 = datetime.now()\n",
    "    dt = (t2-t1).total_seconds()\n",
    "    \n",
    "    preds_train = model.predict(K_train)\n",
    "    preds_test = model.predict(K_test)\n",
    "    \n",
    "    return form_output(model, {}, dt, preds_train, preds_test)\n",
    "\n",
    "def fit_dl_xgb(K_train, K_test, model):\n",
    "    t1 = datetime.now()\n",
    "    model = DecisionLatticeRegressor.from_xgboost(model, K_train)\n",
    "    t2 = datetime.now()\n",
    "    dt = (t2-t1).total_seconds()\n",
    "    \n",
    "    preds_train = model.predict(K_train)\n",
    "    preds_test = model.predict(K_test)\n",
    "    \n",
    "    return form_output(model, {}, dt, preds_train, preds_test)\n",
    "\n",
    "def fit_dl_from_model(K_train, K_test, model):\n",
    "    if isinstance(model, DecisionTreeRegressor):\n",
    "        output = fit_dl_dt(K_train, K_test, model)\n",
    "    elif isinstance(model, RandomForestRegressor):\n",
    "        output = fit_dl_rf(K_train, K_test, model)\n",
    "    elif isinstance(model, GradientBoostingRegressor):\n",
    "        output = fit_dl_gb(K_train, K_test, model)\n",
    "    elif isinstance(model, XGBRegressor):\n",
    "        output = fit_dl_xgb(K_train, K_test, model)\n",
    "    else:\n",
    "        raise ValueError\n",
    "        \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_average_percentage_error(y_true, y_pred):\n",
    "    return np.abs((y_true-y_pred)/y_true).mean()*100\n",
    "def root_mean_squared_percentage_error(y_true, y_pred):\n",
    "    return mean_squared_error(y_true, y_pred, squared=False)/y_true.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_metrics(y_train, y_test, preds_train, preds_test):\n",
    "    metrics_dict = {}\n",
    "    for m_name, m_func in [\n",
    "        ('mse', mean_squared_error),\n",
    "        ('mae', mean_absolute_error),\n",
    "        ('r2',  r2_score),\n",
    "        ('wape', weighted_average_percentage_error),\n",
    "        ('rmse_perc', root_mean_squared_percentage_error)\n",
    "    ]:\n",
    "        for ds_type in ['train', 'test']:\n",
    "            y = y_train if ds_type == 'train' else y_test\n",
    "            p = preds_train if ds_type == 'train' else preds_test\n",
    "            metrics_dict[f\"{m_name}_{ds_type}\"] = m_func(y, p)\n",
    "\n",
    "    return metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_stat_dict(cls, data_name, kf_idx, train_idxs, test_idxs, params, metrics_dict, dt):\n",
    "    stat = {\n",
    "        'model': cls.__name__,\n",
    "        'ds': data_name,\n",
    "        'fold_id': kf_idx,\n",
    "        'train_size': len(train_idxs),\n",
    "        'test_size': len(test_idxs),\n",
    "        'time': dt\n",
    "    }\n",
    "    stat = dict(stat, **{f\"param_{k}\":v for k,v in params.items()})\n",
    "    stat = dict(stat, **{f\"metric_{k}\":v for k,v in metrics_dict.items()})\n",
    "    return stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def form_stat_dict(ens_model_output, dl_model_output, ens_model_metrics, dl_model_metrics, dl_ens_metrics, data_name, kf_idx):\n",
    "    stat = {\n",
    "        'ensemble_model': ens_model_output['model'].__class__.__name__,\n",
    "        'ds': data_name,\n",
    "        'fold_id': kf_idx,\n",
    "        'train_size': len(ens_model_output['preds_train']),\n",
    "        'test_size': len(ens_model_output['preds_test']),\n",
    "        'ensemble_time': ens_model_output['dt'],\n",
    "        'dl_time': dl_model_output['dt'],\n",
    "    }\n",
    "    stat = dict(stat, **{f\"param_{k}\":v for k,v in ens_model_output['params'].items()})\n",
    "    stat = dict(stat, **{f\"ensemble_metric_{k}\":v for k,v in ens_model_metrics.items()})\n",
    "    stat = dict(stat, **{f\"dl_metric_{k}\":v for k,v in dl_model_metrics.items()})\n",
    "    stat = dict(stat, **{f\"dl_ens_metric_{k}\":v for k,v in dl_ens_metrics.items()})\n",
    "    \n",
    "    return stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 42\n",
    "\n",
    "model_params_vars = [\n",
    "    (DecisionTreeRegressor, dict(max_depth=10)),\n",
    "    (RandomForestRegressor, dict(n_estimators=10, max_depth=6)),\n",
    "    (GradientBoostingRegressor, dict(n_estimators=10, max_depth=6)),\n",
    "    (XGBRegressor, dict(n_estimators=10, max_depth=6)),\n",
    "]\n",
    "model_params_vars = [\n",
    "    (cls, dict({'random_state':random_state}, **params))\n",
    "    for cls, params in model_params_vars\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iterate datasets:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "KFold:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "iterate models:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "iterate models:  25%|██▌       | 1/4 [00:25<01:16, 25.35s/it]\u001b[A\u001b[A\n",
      "\n",
      "iterate models:  50%|█████     | 2/4 [03:39<02:31, 75.94s/it]\u001b[A\u001b[A\n",
      "\n",
      "iterate models:  75%|███████▌  | 3/4 [07:04<01:54, 114.64s/it]\u001b[A\u001b[A\n",
      "\n",
      "iterate models: 100%|██████████| 4/4 [10:43<00:00, 146.12s/it]\u001b[A\u001b[A\n",
      "\n",
      "                                                              \u001b[A\u001b[A\n",
      "KFold:  20%|██        | 1/5 [10:44<42:56, 644.20s/it]\u001b[A\n",
      "\n",
      "iterate models:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "iterate models:  25%|██▌       | 1/4 [00:30<01:32, 30.99s/it]\u001b[A\u001b[A\n",
      "\n",
      "iterate models:  50%|█████     | 2/4 [04:16<02:58, 89.28s/it]\u001b[A\u001b[A\n",
      "\n",
      "iterate models:  75%|███████▌  | 3/4 [08:19<02:15, 135.39s/it]\u001b[A\u001b[A\n",
      "\n",
      "iterate models: 100%|██████████| 4/4 [12:04<00:00, 162.49s/it]\u001b[A\u001b[A\n",
      "\n",
      "                                                              \u001b[A\u001b[A\n",
      "KFold:  40%|████      | 2/5 [22:49<33:25, 668.55s/it]\u001b[A\n",
      "\n",
      "iterate models:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "iterate models:  25%|██▌       | 1/4 [00:33<01:39, 33.00s/it]\u001b[A\u001b[A\n",
      "\n",
      "iterate models:  50%|█████     | 2/4 [04:17<03:01, 90.57s/it]\u001b[A\u001b[A\n",
      "\n",
      "iterate models:  75%|███████▌  | 3/4 [07:30<02:01, 121.17s/it]\u001b[A\u001b[A\n",
      "\n",
      "iterate models: 100%|██████████| 4/4 [10:37<00:00, 140.87s/it]\u001b[A\u001b[A\n",
      "\n",
      "                                                              \u001b[A\u001b[A\n",
      "KFold:  60%|██████    | 3/5 [33:27<21:58, 659.32s/it]\u001b[A\n",
      "\n",
      "iterate models:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "iterate models:  25%|██▌       | 1/4 [00:27<01:22, 27.41s/it]\u001b[A\u001b[A\n",
      "\n",
      "iterate models:  50%|█████     | 2/4 [03:28<02:26, 73.37s/it]\u001b[A\u001b[A\n",
      "\n",
      "iterate models:  75%|███████▌  | 3/4 [06:29<01:45, 105.92s/it]\u001b[A\u001b[A\n",
      "\n",
      "iterate models: 100%|██████████| 4/4 [09:38<00:00, 130.76s/it]\u001b[A\u001b[A\n",
      "\n",
      "                                                              \u001b[A\u001b[A\n",
      "KFold:  80%|████████  | 4/5 [43:06<10:35, 635.23s/it]\u001b[A\n",
      "\n",
      "iterate models:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "iterate models:  25%|██▌       | 1/4 [00:30<01:31, 30.43s/it]\u001b[A\u001b[A\n",
      "\n",
      "iterate models:  50%|█████     | 2/4 [03:56<02:46, 83.23s/it]\u001b[A\u001b[A\n",
      "\n",
      "iterate models:  75%|███████▌  | 3/4 [07:06<01:55, 115.16s/it]\u001b[A\u001b[A\n",
      "\n",
      "iterate models: 100%|██████████| 4/4 [10:32<00:00, 142.37s/it]\u001b[A\u001b[A\n",
      "\n",
      "                                                              \u001b[A\u001b[A\n",
      "KFold: 100%|██████████| 5/5 [53:39<00:00, 634.53s/it]\u001b[A\n",
      "iterate datasets:  33%|███▎      | 1/3 [53:39<1:47:18, 3219.28s/it]\n",
      "KFold:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "iterate models:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "iterate models:  25%|██▌       | 1/4 [00:01<00:03,  1.00s/it]\u001b[A\u001b[A\n",
      "\n",
      "iterate models:  50%|█████     | 2/4 [00:08<00:06,  3.10s/it]\u001b[A\u001b[A\n",
      "\n",
      "iterate models:  75%|███████▌  | 3/4 [00:16<00:04,  4.32s/it]\u001b[A\u001b[A\n",
      "\n",
      "iterate models: 100%|██████████| 4/4 [00:23<00:00,  5.15s/it]\u001b[A\u001b[A\n",
      "\n",
      "                                                             \u001b[A\u001b[A\n",
      "KFold:  20%|██        | 1/5 [00:23<01:33, 23.28s/it]\u001b[A\n",
      "\n",
      "iterate models:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "iterate models:  25%|██▌       | 1/4 [00:01<00:03,  1.12s/it]\u001b[A\u001b[A\n",
      "\n",
      "iterate models:  50%|█████     | 2/4 [00:08<00:05,  2.95s/it]\u001b[A\u001b[A\n",
      "\n",
      "iterate models:  75%|███████▌  | 3/4 [00:15<00:04,  4.13s/it]\u001b[A\u001b[A\n",
      "\n",
      "iterate models: 100%|██████████| 4/4 [00:22<00:00,  4.94s/it]\u001b[A\u001b[A\n",
      "\n",
      "                                                             \u001b[A\u001b[A\n",
      "KFold:  40%|████      | 2/5 [00:45<01:08, 22.93s/it]\u001b[A\n",
      "\n",
      "iterate models:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "iterate models:  25%|██▌       | 1/4 [00:01<00:03,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      "iterate models:  50%|█████     | 2/4 [00:08<00:05,  2.88s/it]\u001b[A\u001b[A\n",
      "\n",
      "iterate models:  75%|███████▌  | 3/4 [00:15<00:04,  4.09s/it]\u001b[A\u001b[A\n",
      "\n",
      "iterate models: 100%|██████████| 4/4 [00:22<00:00,  4.94s/it]\u001b[A\u001b[A\n",
      "\n",
      "                                                             \u001b[A\u001b[A\n",
      "KFold:  60%|██████    | 3/5 [01:07<00:45, 22.69s/it]\u001b[A\n",
      "\n",
      "iterate models:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "iterate models:  25%|██▌       | 1/4 [00:01<00:04,  1.39s/it]\u001b[A\u001b[A\n",
      "\n",
      "iterate models:  50%|█████     | 2/4 [00:10<00:07,  3.65s/it]\u001b[A\u001b[A\n",
      "\n",
      "iterate models:  75%|███████▌  | 3/4 [00:18<00:04,  4.98s/it]\u001b[A\u001b[A\n",
      "\n",
      "iterate models: 100%|██████████| 4/4 [00:26<00:00,  5.84s/it]\u001b[A\u001b[A\n",
      "\n",
      "                                                             \u001b[A\u001b[A\n",
      "KFold:  80%|████████  | 4/5 [01:33<00:23, 23.76s/it]\u001b[A\n",
      "\n",
      "iterate models:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "iterate models:  25%|██▌       | 1/4 [00:01<00:03,  1.18s/it]\u001b[A\u001b[A\n",
      "\n",
      "iterate models:  50%|█████     | 2/4 [00:08<00:06,  3.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "iterate models:  75%|███████▌  | 3/4 [00:16<00:04,  4.43s/it]\u001b[A\u001b[A\n",
      "\n",
      "iterate models: 100%|██████████| 4/4 [00:24<00:00,  5.44s/it]\u001b[A\u001b[A\n",
      "\n",
      "                                                             \u001b[A\u001b[A\n",
      "KFold: 100%|██████████| 5/5 [01:57<00:00, 23.85s/it]\u001b[A\n",
      "iterate datasets:  67%|██████▋   | 2/3 [55:37<38:08, 2288.84s/it]  \n",
      "KFold:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "iterate models:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "iterate models:  25%|██▌       | 1/4 [00:00<00:02,  1.06it/s]\u001b[A\u001b[A\n",
      "\n",
      "iterate models:  50%|█████     | 2/4 [00:06<00:04,  2.45s/it]\u001b[A\u001b[A\n",
      "\n",
      "iterate models:  75%|███████▌  | 3/4 [00:12<00:03,  3.36s/it]\u001b[A\u001b[A\n",
      "\n",
      "iterate models: 100%|██████████| 4/4 [00:18<00:00,  4.09s/it]\u001b[A\u001b[A\n",
      "\n",
      "                                                             \u001b[A\u001b[A\n",
      "KFold:  20%|██        | 1/5 [00:18<01:12, 18.21s/it]\u001b[A\n",
      "\n",
      "iterate models:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "iterate models:  25%|██▌       | 1/4 [00:01<00:02,  1.00it/s]\u001b[A\u001b[A\n",
      "\n",
      "iterate models:  50%|█████     | 2/4 [00:06<00:04,  2.45s/it]\u001b[A\u001b[A\n",
      "\n",
      "iterate models:  75%|███████▌  | 3/4 [00:12<00:03,  3.33s/it]\u001b[A\u001b[A\n",
      "\n",
      "iterate models: 100%|██████████| 4/4 [00:17<00:00,  3.95s/it]\u001b[A\u001b[A\n",
      "\n",
      "                                                             \u001b[A\u001b[A\n",
      "KFold:  40%|████      | 2/5 [00:35<00:54, 18.05s/it]\u001b[A\n",
      "\n",
      "iterate models:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "iterate models:  25%|██▌       | 1/4 [00:01<00:03,  1.16s/it]\u001b[A\u001b[A\n",
      "\n",
      "iterate models:  50%|█████     | 2/4 [00:07<00:05,  2.60s/it]\u001b[A\u001b[A\n",
      "\n",
      "iterate models:  75%|███████▌  | 3/4 [00:12<00:03,  3.47s/it]\u001b[A\u001b[A\n",
      "\n",
      "iterate models: 100%|██████████| 4/4 [00:18<00:00,  4.28s/it]\u001b[A\u001b[A\n",
      "\n",
      "                                                             \u001b[A\u001b[A\n",
      "KFold:  60%|██████    | 3/5 [00:54<00:36, 18.28s/it]\u001b[A\n",
      "\n",
      "iterate models:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "iterate models:  25%|██▌       | 1/4 [00:01<00:03,  1.19s/it]\u001b[A\u001b[A\n",
      "\n",
      "iterate models:  50%|█████     | 2/4 [00:07<00:05,  2.64s/it]\u001b[A\u001b[A\n",
      "\n",
      "iterate models:  75%|███████▌  | 3/4 [00:12<00:03,  3.53s/it]\u001b[A\u001b[A\n",
      "\n",
      "iterate models: 100%|██████████| 4/4 [00:18<00:00,  4.18s/it]\u001b[A\u001b[A\n",
      "\n",
      "                                                             \u001b[A\u001b[A\n",
      "KFold:  80%|████████  | 4/5 [01:13<00:18, 18.36s/it]\u001b[A\n",
      "\n",
      "iterate models:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "iterate models:  25%|██▌       | 1/4 [00:00<00:02,  1.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "iterate models:  50%|█████     | 2/4 [00:06<00:04,  2.37s/it]\u001b[A\u001b[A\n",
      "\n",
      "iterate models:  75%|███████▌  | 3/4 [00:12<00:03,  3.31s/it]\u001b[A\u001b[A\n",
      "\n",
      "iterate models: 100%|██████████| 4/4 [00:17<00:00,  3.95s/it]\u001b[A\u001b[A\n",
      "\n",
      "                                                             \u001b[A\u001b[A\n",
      "KFold: 100%|██████████| 5/5 [01:30<00:00, 18.17s/it]\u001b[A\n",
      "iterate datasets: 100%|██████████| 3/3 [57:08<00:00, 1142.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 57min 24s, sys: 1min 2s, total: 58min 26s\n",
      "Wall time: 57min 8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "kf = KFold(n_splits=5)\n",
    "stat_ds = []\n",
    "\n",
    "for data_name, data in tqdm(data_dict.items(), desc='iterate datasets'):\n",
    "    ds, train_feats, cat_feats, y_feat = data['ds'], data['train_feats'], data['cat_feats'], data['y_feat']\n",
    "    train_feats_le = [f+('_le' if f in cat_feats else '') for f in train_feats]\n",
    "    \n",
    "    pattern_types = {f: PS.IntervalPS for f in train_feats_le}\n",
    "\n",
    "    for kf_idx, idxs in tqdm(enumerate(kf.split(ds[train_feats])), desc='KFold', total=kf.n_splits, leave=False):\n",
    "        train_idxs, test_idxs = idxs\n",
    "        ds_train, ds_test = ds.loc[train_idxs], ds.loc[test_idxs]\n",
    "        \n",
    "        #if kf_idx==1:\n",
    "        #    break\n",
    "            \n",
    "        X_train, X_test = ds_train[train_feats_le], ds_test[train_feats_le]\n",
    "        y_train, y_test = ds_train[y_feat], ds_test[y_feat]\n",
    "        \n",
    "        K_train = MVContext(X_train.values, pattern_types, attribute_names=train_feats_le)\n",
    "        K_test = MVContext(X_test.values, pattern_types, attribute_names=train_feats_le)\n",
    "        \n",
    "        for cls, params in tqdm(model_params_vars, leave=False, desc='iterate models'):\n",
    "            ens_model_output = fit_model(X_train, y_train, X_test, params, cls)    \n",
    "            \n",
    "            dl_model_output = fit_dl_from_model(K_train, K_test, ens_model_output['model'])\n",
    "            \n",
    "            ens_metrics = calc_metrics(y_train, y_test, ens_model_output['preds_train'], ens_model_output['preds_test'])\n",
    "            dl_metrics = calc_metrics(y_train, y_test, dl_model_output['preds_train'], dl_model_output['preds_test'])\n",
    "            \n",
    "            dl_ens_metrics = calc_metrics(ens_model_output['preds_train'], ens_model_output['preds_test'], \n",
    "                                          dl_model_output['preds_train'], dl_model_output['preds_test'])\n",
    "            \n",
    "            \n",
    "            stat = form_stat_dict(ens_model_output, dl_model_output, ens_metrics, dl_metrics, dl_ens_metrics, data_name, kf_idx)\n",
    "            stat_ds.append(pd.Series(stat))\n",
    "            \n",
    "                                    \n",
    "                    \n",
    "        pd.concat(stat_ds,1, sort=False).T.to_csv('tmp_evaluation_regr.csv')\n",
    "pd.concat(stat_ds,1, sort=False).T.to_csv('evaluation_regr_full_10est6depth.csv')\n",
    "!rm tmp_evaluation_regr.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
